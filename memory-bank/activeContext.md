# アクティブコンテキスト

## 現在の作業の焦点

**リアルタイム通信（WebSocket/SSE）の実装が完了しました！** ストリーミング応答機能を含む完全なWebSocket通信システムを実装し、ユーザーはLLMからの応答をリアルタイムで確認できるようになりました。これにより、プロダクション品質のリアルタイムLLMチャットアプリケーションとして完全に動作しています。

## 最近の変更

*   **✅ リアルタイム通信（WebSocket/SSE）実装完了**:
    *   WebSocketエンドポイント（`/api/websocket/ws/{client_id}`）の実装
    *   全LLMプロバイダー（OpenAI、Anthropic、Gemini、Ollama）でのストリーミング応答対応
    *   WebSocket接続管理とエラーハンドリング
    *   自動再接続機能付きWebSocketクライアント実装

*   **✅ バックエンド実装詳細**:
    *   **WebSocketルーター**: `backend/src/backend/routers/websocket_chat.py`
        - ConnectionManagerクラスによる接続管理
        - リアルタイムメッセージ処理
        - ストリーミング応答の配信
    *   **LLMサービス拡張**: `backend/src/backend/llm_service.py`
        - `generate_streaming_response`メソッド追加
        - 各プロバイダー用ストリーミングメソッド実装
        - OpenAI: ネイティブストリーミング対応
        - Anthropic: ネイティブストリーミング対応
        - Gemini: 疑似ストリーミング（単語分割）
        - Ollama: ネイティブストリーミング対応

*   **✅ フロントエンド実装詳細**:
    *   **WebSocketクライアント**: `frontend/src/lib/websocket.ts`
        - 自動接続・再接続機能
        - メッセージハンドリングシステム
        - 接続状態管理
    *   **会話ストア拡張**: `frontend/src/store/conversationStore.ts`
        - `sendMessageViaWebSocket`メソッド追加
        - ストリーミング状態管理（`isStreaming`, `streamingNodeId`）
        - WebSocket接続状態管理（`isWebSocketConnected`）
        - リアルタイムメッセージ更新機能

*   **✅ UI/UX改善**:
    *   **MessageInput**: `frontend/src/components/MessageInput.tsx`
        - 通信モード切り替えボタン（WebSocket ⇔ HTTP API）
        - 接続状態の視覚的表示（接続済み/未接続）
        - ストリーミング中の状態表示
    *   **MessageList**: `frontend/src/components/MessageList.tsx`
        - ストリーミング中のリアルタイム応答表示
        - 入力中アニメーション（点滅カーソル、バウンスドット）
        - 自動スクロール機能
        - ストリーミング中のメッセージ強調表示

*   **✅ 動作確認完了**:
    *   バックエンドサーバー起動（http://localhost:8000）
    *   フロントエンドサーバー起動（http://localhost:3000）
    *   WebSocket接続の自動確立
    *   実際のLLM（Ollama）でのストリーミング応答テスト
    *   HTTP APIとWebSocketの切り替え機能テスト
    *   チャット履歴タイトル自動更新機能の継続動作確認

*   **✅ 以前の完了済み機能**:
    *   チャット履歴タイトル自動更新機能
    *   設定画面の構造改善（プロバイダータイプベース設計）
    *   APIキー検証とエラーハンドリング強化
    *   Azure OpenAIサポート追加
    *   モデル切り替え機能の完全実装
    *   Ollamaプロバイダーエラー修正
    *   ダークモード問題修正
    *   フロントエンドとバックエンドのワンショット起動設定

## 次のステップ

1.  **✅ 完了: 設定画面の構造改善**
2.  **✅ 完了: プロバイダー管理機能の実装**
3.  **✅ 完了: APIキー検証とエラーハンドリング**
4.  **✅ 完了: フロントエンドとバックエンドのサーバーをワンショットで起動する設定**
5.  **✅ 完了: WebSocket/SSE通信の実装（リアルタイム応答）**
6.  **✅ 完了: ストリーミング応答の実装**
7.  認証・認可機能の追加（必要に応じて）
8.  パフォーマンス最適化とキャッシュ機能
9.  エクスポート/インポート機能

## アクティブな決定と考慮事項

*   **リアルタイム通信アーキテクチャ**: WebSocketベースのストリーミング通信システム
*   **フォールバック戦略**: WebSocket接続失敗時のHTTP API自動切り替え
*   **ストリーミング応答管理**: プロバイダー別のストリーミング実装とUI連携
*   **接続状態管理**: 視覚的フィードバックと自動再接続機能
*   **設定管理アーキテクチャ**: プロバイダータイプベースの統一設定システム
*   **状態管理**: Zustandによるローカル設定とバックエンドAPIの連携
*   **エラーハンドリング**: 段階的なエラー検証（フロントエンド→バックエンド→LLM API）
*   **プロバイダー抽象化**: 統一インターフェースで5つのLLMプロバイダーに対応

## 重要なパターンと好み

*   **WebSocket通信パターン**: 自動接続・再接続、メッセージタイプベースルーティング
*   **ストリーミングUIパターン**: リアルタイム更新、視覚的フィードバック、自動スクロール
*   **通信モード切り替え**: ユーザーが選択可能なWebSocket/HTTP API切り替え
*   **プロバイダー設定パターン**: タイプベースの設定管理で拡張性を確保
*   **APIキー管理**: セキュアな検証とエラーメッセージの実装
*   **UI/UXパターン**: 直感的なアイコン、ローディング状態、エラー表示
*   **非同期処理**: async/awaitによる適切な非同期処理実装
*   **型安全性**: TypeScriptによる厳密な型定義と検証

## 学習とプロジェクトの洞察

*   **WebSocket実装**: FastAPIのWebSocket機能とReactの状態管理の効果的な連携
*   **ストリーミング応答**: プロバイダー別の実装差異を統一インターフェースで吸収
*   **リアルタイムUI**: ストリーミング中の視覚的フィードバックによるUX向上
*   **接続管理**: 自動再接続とフォールバック機能による堅牢性確保
*   **設定画面設計**: プロバイダータイプベースの設計により保守性と拡張性が向上
*   **エラーハンドリング戦略**: 段階的な検証により適切なエラーメッセージを提供
*   **状態管理パターン**: Zustandの永続化機能とバックエンドAPIの効果的な連携
*   **プロバイダー抽象化**: 統一インターフェースにより新しいプロバイダーの追加が容易

## 実装済み機能

### WebSocket通信システム
*   **WebSocketエンドポイント**: `/api/websocket/ws/{client_id}`
*   **接続管理**: ConnectionManagerによる複数クライアント管理
*   **メッセージルーティング**: タイプベースのメッセージ処理
*   **自動再接続**: 接続断時の自動復旧機能
*   **エラーハンドリング**: WebSocket固有のエラー処理

### ストリーミング応答システム
*   **OpenAI**: ネイティブストリーミング（`stream=True`）
*   **Anthropic**: ネイティブストリーミング（`client.messages.stream`）
*   **Gemini**: 疑似ストリーミング（単語分割 + 遅延）
*   **Ollama**: ネイティブストリーミング（`stream=True`）
*   **統一インターフェース**: `generate_streaming_response`メソッド

### リアルタイムUI
*   **通信モード切り替え**: WebSocket（ストリーミング）⇔ HTTP API
*   **接続状態表示**: 視覚的インジケーター（緑/赤ドット）
*   **ストリーミング表示**: リアルタイム応答更新、入力中アニメーション
*   **自動スクロール**: 新しいメッセージへの自動追従
*   **視覚的フィードバック**: ストリーミング中の強調表示

### 設定画面（SettingsModal）
*   **プロバイダータイプ管理**:
    *   🤖 OpenAI (gpt-4o)
    *   ☁️ Azure OpenAI (gpt-4)
    *   💎 Google Gemini (gemini-pro)
    *   🧠 Anthropic Claude (claude-3-sonnet-20240229)
    *   🦙 Ollama (llama2:latest)

*   **設定項目**:
    *   プロバイダー名とモデル名の編集
    *   APIキー設定（Ollama以外）
    *   ベースURL設定（OllamaとAzure）
    *   有効/無効の切り替え
    *   アクティブプロバイダーの選択

*   **UI機能**:
    *   ローディング状態表示
    *   エラーメッセージ表示
    *   リアルタイム設定保存
    *   非同期処理対応

### バックエンドLLMサービス
*   **プロバイダー判定**: 名前とモデル名による自動判定
*   **Azure OpenAI対応**: OpenAI APIと同じ処理で実装
*   **APIキー検証**: 無効なキーの検出と適切なエラーメッセージ
*   **クライアントキャッシュ**: プロバイダーごとのクライアント管理
*   **エラーハンドリング**: プロバイダー固有のエラー処理
*   **ストリーミング対応**: 全プロバイダーでのストリーミング応答実装

### フロントエンド状態管理
*   **設定ストア**: プロバイダー設定の永続化とAPI連携
*   **会話ストア**: WebSocket通信とストリーミング状態管理
*   **型安全性**: TypeScriptによる厳密な型定義
*   **非同期処理**: async/awaitによる適切な処理
*   **エラー管理**: 段階的なエラーハンドリング

## 動作確認済み機能

*   ✅ WebSocketリアルタイム通信
*   ✅ ストリーミング応答（全LLMプロバイダー対応）
*   ✅ 通信モード切り替え（WebSocket ⇔ HTTP API）
*   ✅ 接続状態の視覚的表示
*   ✅ 自動再接続機能
*   ✅ リアルタイムUI更新と自動スクロール
*   ✅ チャット履歴タイトル自動更新機能
*   ✅ プロバイダータイプベースの設定画面
*   ✅ APIキー検証とエラーメッセージ表示
*   ✅ Azure OpenAIサポート
*   ✅ モデル切り替え機能（Qwen3 ↔ LLaMA2）
*   ✅ 削除機能とJSON解析エラー修正
*   ✅ 設定の永続化とAPI連携
*   ✅ ローディング状態とエラー表示
*   ✅ 非同期処理の適切な実装
*   ✅ Ollamaプロバイダーエラー修正
*   ✅ ダークモード問題修正
*   ✅ フロントエンドとバックエンドの同時起動
